<!DOCTYPE html>
<html lang="en-us" dir="ltr">
<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<meta name="description" content="Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE # Students: # Yazan Kbaili ( y.kbaili@innopolis.university) Hamada Salhab ( h.salhab@innopolis.university) Introduction # This report delves into the visualization of sentence embeddings derived from the roberta-base model fine-tuned on the &ldquo;go-emotion&rdquo; dataset using two prominent dimensionality reduction techniques: UMAP (Uniform Manifold Approximation and Projection) and t-SNE (t-distributed Stochastic Neighbor Embedding). The dataset used in the visualization consists of Twitter messages and is called “emotions”.">
<meta name="theme-color" content="#FFFFFF">
<meta name="color-scheme" content="light dark"><meta property="og:url" content="http://localhost:1313/docs/groups/dimensionality-reduction-in-nlp-visualizing-sentence-embeddings-with-umap-and-t-sne/">
  <meta property="og:site_name" content="XAI">
  <meta property="og:title" content="Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE">
  <meta property="og:description" content="Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE # Students: # Yazan Kbaili ( y.kbaili@innopolis.university) Hamada Salhab ( h.salhab@innopolis.university) Introduction # This report delves into the visualization of sentence embeddings derived from the roberta-base model fine-tuned on the “go-emotion” dataset using two prominent dimensionality reduction techniques: UMAP (Uniform Manifold Approximation and Projection) and t-SNE (t-distributed Stochastic Neighbor Embedding). The dataset used in the visualization consists of Twitter messages and is called “emotions”.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="docs">
<title>Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE | XAI</title>
<link rel="manifest" href="/manifest.json">
<link rel="icon" href="/favicon.png" type="image/x-icon">
<link rel="stylesheet" href="/book.min.e832d4e94212199857473bcf13a450d089c3fcd54ccadedcfac84ed0feff83fb.css" integrity="sha256-6DLU6UISGZhXRzvPE6RQ0InD/NVMyt7c&#43;shO0P7/g/s=" crossorigin="anonymous">
<script defer src="https://cdn.jsdelivr.net/npm/katex@0.16.4/dist/contrib/mathtex-script-type.min.js" integrity="sha384-jiBVvJ8NGGj5n7kJaiWwWp9AjC+Yh8rhZY3GtAX8yU28azcLgoRo4oukO87g7zDT" crossorigin="anonymous"></script>
  <script defer src="/flexsearch.min.js"></script>
  <script defer src="/en.search.min.690e50761b66b2e4cf12ec5df41f0c40cac7f8b58f42e8845ad4158a9deab588.js" integrity="sha256-aQ5QdhtmsuTPEuxd9B8MQMrH&#43;LWPQuiEWtQVip3qtYg=" crossorigin="anonymous"></script>

  <script defer src="/sw.min.6f6f90fcb8eb1c49ec389838e6b801d0de19430b8e516902f8d75c3c8bd98739.js" integrity="sha256-b2&#43;Q/LjrHEnsOJg45rgB0N4ZQwuOUWkC&#43;NdcPIvZhzk=" crossorigin="anonymous"></script>

  

<!--
Made with Book Theme
https://github.com/alex-shpak/hugo-book
-->
  
</head>
<body dir="ltr">
  <input type="checkbox" class="hidden toggle" id="menu-control" />
  <input type="checkbox" class="hidden toggle" id="toc-control" />
  <main class="container flex">
    <aside class="book-menu">
      <div class="book-menu-content">
        
  <nav>
<h2 class="book-brand">
  <a class="flex align-center" href="/"><img src="/YELLOW_BAR.png" alt="Logo" /><span><b>XAI</b></span>
  </a>
</h2>


<div class="book-search">
  <input type="text" id="book-search-input" placeholder="Search" aria-label="Search" maxlength="64" data-hotkeys="s/" />
  <div class="book-search-spinner hidden"></div>
  <ul id="book-search-results"></ul>
</div>












  



  
  <ul>
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/cam_and_secam/" class="">CAM and SeCAM</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/diffusion-lens-interpreting-text-encoders-in-text-to-image-pipelines-tuned-using-dreambooth/" class="">Diffusion Lens: Interpreting Text Encoders in Text-to-Image pipelines</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/dimensionality-reduction-in-nlp-visualizing-sentence-embeddings-with-umap-and-t-sne/" class="active">Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/example/" class="">Example</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/ai-playing-geoguessr-explained/" class="">Ai Playing Geo Guessr Explained</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/contrastive-grad-cam-consistency/" class="">Contrastive Grad Cam Consistency</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/dndfs_shap/" class="">Dndfs Shap</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/gradcam/" class="">Grad Cam</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/integrated-gradients/" class="">Integrated Gradients</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/kernel-shap/" class="">Kernel Shap</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/rag/" class="">Rag</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/shap_darya_and_viktoria/" class="">Shap Darya and Viktoria</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/sverl_tac_toe/" class="">Sverl Tac Toe</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/torchprism/" class="">Torch Prism</a>
  

        </li>
      
    
      
        <li>
          
  
  

  
    <a href="/docs/groups/xai_for_transformers/" class="">Xai for Transformers</a>
  

        </li>
      
    
  </ul>















</nav>




  <script>(function(){var e=document.querySelector("aside .book-menu-content");addEventListener("beforeunload",function(){localStorage.setItem("menu.scrollTop",e.scrollTop)}),e.scrollTop=localStorage.getItem("menu.scrollTop")})()</script>


 
      </div>
    </aside>

    <div class="book-page">
      <header class="book-header">
        
  <div class="flex align-center justify-between">
  <label for="menu-control">
    <img src="/svg/menu.svg" class="book-icon" alt="Menu" />
  </label>

  <strong>Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE</strong>

  <label for="toc-control">
    
    <img src="/svg/toc.svg" class="book-icon" alt="Table of Contents" />
    
  </label>
</div>


  
  <aside class="hidden clearfix">
    
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#dimensionality-reduction-in-nlp-visualizing-sentence-embeddings-with-umap-and-t-sne">Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE</a>
      <ul>
        <li><a href="#students">Students:</a></li>
        <li><a href="#introduction">Introduction</a></li>
        <li><a href="#methodology">Methodology</a>
          <ul>
            <li><a href="#umap">UMAP</a></li>
            <li><a href="#t-sne">t-SNE</a></li>
            <li><a href="#umap-vs-t-sne">UMAP vs t-SNE</a></li>
          </ul>
        </li>
        <li><a href="#extraction-of-embeddings">Extraction of Embeddings</a></li>
        <li><a href="#visualization">Visualization</a>
          <ul>
            <li><a href="#t-sne-1">t-SNE</a></li>
            <li><a href="#umap-1">UMAP</a></li>
          </ul>
        </li>
        <li><a href="#insights">Insights</a></li>
        <li><a href="#extra-insights">Extra Insights</a></li>
        <li><a href="#applications">Applications</a></li>
        <li><a href="#colab-notebook">Colab Notebook</a></li>
        <li><a href="#presentation-slides">Presentation Slides</a></li>
      </ul>
    </li>
  </ul>
</nav>



  </aside>
  
 
      </header>

      
      
  <article class="markdown"><h1 id="dimensionality-reduction-in-nlp-visualizing-sentence-embeddings-with-umap-and-t-sne">
  Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE
  <a class="anchor" href="#dimensionality-reduction-in-nlp-visualizing-sentence-embeddings-with-umap-and-t-sne">#</a>
</h1>
<h2 id="students">
  Students:
  <a class="anchor" href="#students">#</a>
</h2>
<ul>
<li>Yazan Kbaili (
  <a href="mailto:y.kbaili@innopolis.university">y.kbaili@innopolis.university</a>)</li>
<li>Hamada Salhab (
  <a href="mailto:h.salhab@innopolis.university">h.salhab@innopolis.university</a>)</li>
</ul>
<h2 id="introduction">
  Introduction
  <a class="anchor" href="#introduction">#</a>
</h2>
<p>This report delves into the visualization of sentence embeddings derived from the <code>roberta-base</code> model fine-tuned on the &ldquo;go-emotion&rdquo; dataset using two prominent dimensionality reduction techniques: UMAP (Uniform Manifold Approximation and Projection) and t-SNE (t-distributed Stochastic Neighbor Embedding). The dataset used in the visualization consists of Twitter messages and is called “emotions”.</p>
<h2 id="methodology">
  Methodology
  <a class="anchor" href="#methodology">#</a>
</h2>
<p>The embeddings were generated by the <code>roberta-base</code> model, specifically tailored for multiclass emotion classification and accessible via Hugging Face. This model is particularly adept at interpreting emotional contexts within text, making it highly suitable for our study. We focus on embeddings from Twitter messages categorized into six distinct emotions.</p>
<h3 id="umap">
  UMAP
  <a class="anchor" href="#umap">#</a>
</h3>
<p>Operates on a foundation of algebraic topology, creating a high-dimensional graph representation of data before optimizing this layout in a lower-dimensional space. It aims to preserve both local and global structures, offering a comprehensive data understanding. UMAP is generally preferred for its ability to maintain a more global structure compared to t-SNE.</p>
<h3 id="t-sne">
  t-SNE
  <a class="anchor" href="#t-sne">#</a>
</h3>
<p>Transforms high-dimensional Euclidean distances between points into conditional probabilities that reflect similarities, excelling in the preservation of local data structures and the identification of clusters. While effective, t-SNE can be computationally demanding, especially with large datasets, and may exaggerate cluster separations without maintaining global data integrity.</p>
<h3 id="umap-vs-t-sne">
  UMAP vs t-SNE
  <a class="anchor" href="#umap-vs-t-sne">#</a>
</h3>
<p>The behavior of t-SNE and UMAP differs significantly in terms of initialization and the iterative process used to optimize the low-dimensional representation. Below are some of the key differences:</p>
<table>
<thead>
<tr>
<th>Feature</th>
<th>t-SNE</th>
<th>UMAP</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Initialization</strong></td>
<td>Starts with a random initialization of the graph.</td>
<td>Uses Spectral Embedding for deterministic initialization.</td>
</tr>
<tr>
<td><strong>Iteration Process</strong></td>
<td>Moves every single point slightly each iteration.</td>
<td>Can move just one point or a small subset of points each time.</td>
</tr>
<tr>
<td><strong>Scalability</strong></td>
<td>Less efficient with very large datasets.</td>
<td>Scales well with large datasets due to its partial update approach.</td>
</tr>
</tbody>
</table>
<h2 id="extraction-of-embeddings">
  Extraction of Embeddings
  <a class="anchor" href="#extraction-of-embeddings">#</a>
</h2>
<p>We utilized the embedding from the last token at the last layer of the pre-trained model, which typically encapsulates the sentence&rsquo;s contextual essence.</p>
<h2 id="visualization">
  Visualization
  <a class="anchor" href="#visualization">#</a>
</h2>
<p>For an interactive visual representation, we employed Plotly, enabling detailed exploration of the structures within the embeddings.</p>
<h3 id="t-sne-1">
  t-SNE
  <a class="anchor" href="#t-sne-1">#</a>
</h3>
<p>1:

  <img src="https://hackmd.io/_uploads/Hy0VHwm7R.png" alt="image" />
2:

  <img src="https://hackmd.io/_uploads/H1a6ul7mC.png" alt="t-SNE" /></p>
<h3 id="umap-1">
  UMAP
  <a class="anchor" href="#umap-1">#</a>
</h3>
<p>1:

  <img src="https://hackmd.io/_uploads/BkaTOg77A.png" alt="UMAP1" />
2:

  <img src="https://hackmd.io/_uploads/rJ66_xm7C.png" alt="UMAP2" /></p>
<h2 id="insights">
  Insights
  <a class="anchor" href="#insights">#</a>
</h2>
<p>The visualizations above show that the dimensionality reduction methods used did a reasonably good job with clustering the different labels of data. Note that the model is trained on a different dataset, and has never seen the data we tried it, which explain the limiatation and</p>
<h2 id="extra-insights">
  Extra Insights
  <a class="anchor" href="#extra-insights">#</a>
</h2>
<p>Let&rsquo;s take a look at this 2D visualization from UMAP:</p>
<p>
  <img src="https://hackmd.io/_uploads/ryWD9P7QR.jpg" alt="telegram-cloud-photo-size-4-5922267642553550056-y" /></p>
<ul>
<li>We zoomed in to the cluster highlighted in red, and found out that altough it contains sentences that belong to all labels, all of them convey some sort of regret/guilt.</li>
</ul>
<p>
  <img src="https://hackmd.io/_uploads/Hk25Xv7XC.png" alt="image" /></p>
<ul>
<li>
<p>We took another look at the cluster highlighted in yellow, and saw that all the sentences there talk about humiliation/disgrace.

  <img src="https://hackmd.io/_uploads/r1pTwD7XC.png" alt="image" /></p>
</li>
<li>
<p>As for the cluster highlighted in black, all the sentences conveyed meaning for the purpose of thanking and appreciation.

  <img src="https://hackmd.io/_uploads/Hyw39PXQ0.png" alt="image" /></p>
</li>
</ul>
<h2 id="applications">
  Applications
  <a class="anchor" href="#applications">#</a>
</h2>
<ul>
<li><strong>Model Debugging and Improvement</strong>: Identifies anomalies or biases in embeddings, facilitating targeted improvements to the model.</li>
<li><strong>Semantic Analysis</strong>: Assists in understanding how sentences are clustered semantically, which helps in tasks such as sentiment analysis.</li>
<li><strong>Transfer Learning Insights</strong>: Offers insights into the transferability of learned features, especially in domain-specific applications.</li>
<li><strong>Multilingual Comparisons</strong>: Evaluates the model’s capability across different languages, which helps identify potential biases or gaps.</li>
<li><strong>Explainability and Trust</strong>: Increases the transparency of NLP systems, and builds trust among end-users and regulators by making complex models more interpretable.</li>
</ul>
<h2 id="colab-notebook">
  Colab Notebook
  <a class="anchor" href="#colab-notebook">#</a>
</h2>
<p>The source code for this project can be found in this 
  <a href="https://colab.research.google.com/drive/1rs08XMn38GFz2bcOKXdCJJUKrh8rgNHF#scrollTo=cSbyb4wbtCZn">Colab Notebook</a>.</p>
<h2 id="presentation-slides">
  Presentation Slides
  <a class="anchor" href="#presentation-slides">#</a>
</h2>
<p>The presentation slides for this project can be found on 
  <a href="https://docs.google.com/presentation/d/1Bclphb2ixuRuoXJU4qDmzm6ohTTB1fOEBakchy19y4g/edit?usp=sharing">Google Slides</a>.</p>
</article>
 
      

      <footer class="book-footer">
        
  <div class="flex flex-wrap justify-between">




  <div>
    <a class="flex align-center" href="https://github.com/IU-PR/Capstone_project/tree/master//content/docs/Groups/Dimensionality%20Reduction%20in%20NLP:%20Visualizing%20Sentence%20Embeddings%20with%20UMAP%20and%20t-SNE.md" target="_blank" rel="noopener">
      <img src="/svg/edit.svg" class="book-icon" alt="Edit" />
      <span>Edit this page</span>
    </a>
  </div>


</div>



  <script>(function(){function e(e){const t=window.getSelection(),n=document.createRange();n.selectNodeContents(e),t.removeAllRanges(),t.addRange(n)}document.querySelectorAll("pre code").forEach(t=>{t.addEventListener("click",function(){if(window.getSelection().toString())return;e(t.parentElement),navigator.clipboard&&navigator.clipboard.writeText(t.parentElement.textContent)})})})()</script>


 
        
      </footer>

      
  
  <div class="book-comments">

</div>
  
 

      <label for="menu-control" class="hidden book-menu-overlay"></label>
    </div>

    
    <aside class="book-toc">
      <div class="book-toc-content">
        
  
<nav id="TableOfContents">
  <ul>
    <li><a href="#dimensionality-reduction-in-nlp-visualizing-sentence-embeddings-with-umap-and-t-sne">Dimensionality Reduction in NLP: Visualizing Sentence Embeddings with UMAP and t-SNE</a>
      <ul>
        <li><a href="#students">Students:</a></li>
        <li><a href="#introduction">Introduction</a></li>
        <li><a href="#methodology">Methodology</a>
          <ul>
            <li><a href="#umap">UMAP</a></li>
            <li><a href="#t-sne">t-SNE</a></li>
            <li><a href="#umap-vs-t-sne">UMAP vs t-SNE</a></li>
          </ul>
        </li>
        <li><a href="#extraction-of-embeddings">Extraction of Embeddings</a></li>
        <li><a href="#visualization">Visualization</a>
          <ul>
            <li><a href="#t-sne-1">t-SNE</a></li>
            <li><a href="#umap-1">UMAP</a></li>
          </ul>
        </li>
        <li><a href="#insights">Insights</a></li>
        <li><a href="#extra-insights">Extra Insights</a></li>
        <li><a href="#applications">Applications</a></li>
        <li><a href="#colab-notebook">Colab Notebook</a></li>
        <li><a href="#presentation-slides">Presentation Slides</a></li>
      </ul>
    </li>
  </ul>
</nav>


 
      </div>
    </aside>
    
  </main>

  
</body>
</html>












